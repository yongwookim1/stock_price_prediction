{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e6f4617",
      "metadata": {
        "id": "4e6f4617"
      },
      "source": [
        "### 1. Load stock price data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4d745e78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "4d745e78",
        "outputId": "a962500f-8ea3-4c1b-fa93-42f80025601b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Close    Volume  Good  Bad  Intermediate\n",
              "0  72000.0  13227285     1    0             0\n",
              "1  71900.0  12541046     0    0             1\n",
              "2  71500.0  13614994     1    0             0\n",
              "3  71800.0  15373696     1    0             0\n",
              "4  71200.0  11100887     0    0             1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-144a23e5-3434-4dcf-9a9a-82a471a43a7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Good</th>\n",
              "      <th>Bad</th>\n",
              "      <th>Intermediate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>72000.0</td>\n",
              "      <td>13227285</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71900.0</td>\n",
              "      <td>12541046</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71500.0</td>\n",
              "      <td>13614994</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>71800.0</td>\n",
              "      <td>15373696</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71200.0</td>\n",
              "      <td>11100887</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-144a23e5-3434-4dcf-9a9a-82a471a43a7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-144a23e5-3434-4dcf-9a9a-82a471a43a7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-144a23e5-3434-4dcf-9a9a-82a471a43a7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1952525d-a8a1-438f-82a4-2261d0530127\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1952525d-a8a1-438f-82a4-2261d0530127')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1952525d-a8a1-438f-82a4-2261d0530127 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 245,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4154.034103239873,\n        \"min\": 66000.0,\n        \"max\": 85300.0,\n        \"num_unique_values\": 116,\n        \"samples\": [\n          78900.0,\n          71200.0,\n          70700.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7129385,\n        \"min\": 2957915,\n        \"max\": 57691266,\n        \"num_unique_values\": 245,\n        \"samples\": [\n          10060049,\n          10626603,\n          11737747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Good\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intermediate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Set ticker\n",
        "ticker = '005930.KS'\n",
        "\n",
        "# Load Data\n",
        "stock_data = yf.download(ticker, start='2023-06-13', end='2024-06-13')\n",
        "news_data = pd.read_csv('/content/news_data.csv')\n",
        "dates = stock_data.index\n",
        "\n",
        "# data = stock_data[['Close', 'Volume']]\n",
        "\n",
        "# Convert the Date column to datetime in both datasets\n",
        "news_data['Date'] = pd.to_datetime(news_data['Date'])\n",
        "\n",
        "# Convert the index to a column\n",
        "stock_data.reset_index(inplace=True)\n",
        "\n",
        "# Rename the index column to 'Date'\n",
        "stock_data.rename(columns={'index': 'Date'}, inplace=True)\n",
        "\n",
        "# Convert the Date column to datetime\n",
        "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
        "\n",
        "# Merge the datasets on the Date column\n",
        "data = pd.merge(stock_data, news_data, on='Date', how='inner')\n",
        "data = data[['Close', 'Volume', 'Good', 'Bad', 'Intermediate']]\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea3f91ec",
      "metadata": {
        "id": "ea3f91ec"
      },
      "source": [
        "### 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98d9fc7b",
      "metadata": {
        "id": "98d9fc7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0de9fe-578b-459c-fe8f-0fc7a7e3d100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(148, 60, 5) (148,)\n",
            "(19, 60, 5) (19,)\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "\n",
        "# Create sequence data\n",
        "def create_sequences(data, seq_length):\n",
        "    xs, ys = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        x = data[i : i + seq_length]\n",
        "        y = data[i + seq_length][0]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "\n",
        "seq_length = 60\n",
        "X, y = create_sequences(scaled_data, seq_length)\n",
        "\n",
        "# Split data\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "split = int(0.5 * len(X_test))\n",
        "X_valid, X_test = X_test[:split], X_test[split:]\n",
        "y_valid, y_test = y_test[:split], y_test[split:]\n",
        "\n",
        "# Save dates of test data\n",
        "test_dates = dates[-19:]\n",
        "\n",
        "# Check a shape of data\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "# Set DataLoader\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_data = TensorDataset(\n",
        "    torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float()\n",
        ")\n",
        "valid_data = TensorDataset(\n",
        "    torch.from_numpy(X_valid).float(), torch.from_numpy(y_valid).float()\n",
        ")\n",
        "test_data = TensorDataset(\n",
        "    torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad833cd3",
      "metadata": {
        "id": "ad833cd3"
      },
      "source": [
        "### 3. Define LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8adcf95c",
      "metadata": {
        "id": "8adcf95c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "class StockPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(StockPredictor, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "input_size = 5  # Close, Volume, Good, Bad, Intermediate\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = StockPredictor(input_size, hidden_size, num_layers).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7255b0e",
      "metadata": {
        "id": "a7255b0e"
      },
      "source": [
        "### 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f3bf266c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f3bf266c",
        "outputId": "f2b6d7da-ed8f-418f-e1d4-684a80146550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000]\n",
            "Train Loss: 0.0454\n",
            "Valid Loss: 0.1051\n",
            "Epoch [2/1000]\n",
            "Train Loss: 0.0627\n",
            "Valid Loss: 0.0291\n",
            "Epoch [3/1000]\n",
            "Train Loss: 0.0546\n",
            "Valid Loss: 0.0366\n",
            "Epoch [4/1000]\n",
            "Train Loss: 0.0410\n",
            "Valid Loss: 0.0529\n",
            "Epoch [5/1000]\n",
            "Train Loss: 0.0433\n",
            "Valid Loss: 0.0587\n",
            "Epoch [6/1000]\n",
            "Train Loss: 0.0382\n",
            "Valid Loss: 0.0356\n",
            "Epoch [7/1000]\n",
            "Train Loss: 0.0248\n",
            "Valid Loss: 0.0142\n",
            "Epoch [8/1000]\n",
            "Train Loss: 0.0255\n",
            "Valid Loss: 0.0117\n",
            "Epoch [9/1000]\n",
            "Train Loss: 0.0155\n",
            "Valid Loss: 0.0432\n",
            "Epoch [10/1000]\n",
            "Train Loss: 0.0105\n",
            "Valid Loss: 0.1526\n",
            "Epoch [11/1000]\n",
            "Train Loss: 0.0095\n",
            "Valid Loss: 0.2605\n",
            "Epoch [12/1000]\n",
            "Train Loss: 0.0149\n",
            "Valid Loss: 0.0415\n",
            "Epoch [13/1000]\n",
            "Train Loss: 0.0082\n",
            "Valid Loss: 0.0505\n",
            "Epoch [14/1000]\n",
            "Train Loss: 0.0092\n",
            "Valid Loss: 0.0219\n",
            "Epoch [15/1000]\n",
            "Train Loss: 0.0119\n",
            "Valid Loss: 0.0274\n",
            "Epoch [16/1000]\n",
            "Train Loss: 0.0112\n",
            "Valid Loss: 0.0450\n",
            "Epoch [17/1000]\n",
            "Train Loss: 0.0079\n",
            "Valid Loss: 0.0374\n",
            "Epoch [18/1000]\n",
            "Train Loss: 0.0072\n",
            "Valid Loss: 0.0436\n",
            "Epoch [19/1000]\n",
            "Train Loss: 0.0093\n",
            "Valid Loss: 0.0174\n",
            "Epoch [20/1000]\n",
            "Train Loss: 0.0046\n",
            "Valid Loss: 0.0283\n",
            "Epoch [21/1000]\n",
            "Train Loss: 0.0077\n",
            "Valid Loss: 0.0159\n",
            "Epoch [22/1000]\n",
            "Train Loss: 0.0099\n",
            "Valid Loss: 0.0220\n",
            "Epoch [23/1000]\n",
            "Train Loss: 0.0150\n",
            "Valid Loss: 0.0166\n",
            "Epoch [24/1000]\n",
            "Train Loss: 0.0075\n",
            "Valid Loss: 0.0162\n",
            "Epoch [25/1000]\n",
            "Train Loss: 0.0061\n",
            "Valid Loss: 0.0142\n",
            "Epoch [26/1000]\n",
            "Train Loss: 0.0058\n",
            "Valid Loss: 0.0136\n",
            "Epoch [27/1000]\n",
            "Train Loss: 0.0066\n",
            "Valid Loss: 0.0102\n",
            "Epoch [28/1000]\n",
            "Train Loss: 0.0072\n",
            "Valid Loss: 0.0104\n",
            "Epoch [29/1000]\n",
            "Train Loss: 0.0043\n",
            "Valid Loss: 0.0112\n",
            "Epoch [30/1000]\n",
            "Train Loss: 0.0059\n",
            "Valid Loss: 0.0108\n",
            "Epoch [31/1000]\n",
            "Train Loss: 0.0077\n",
            "Valid Loss: 0.0109\n",
            "Epoch [32/1000]\n",
            "Train Loss: 0.0044\n",
            "Valid Loss: 0.0119\n",
            "Epoch [33/1000]\n",
            "Train Loss: 0.0057\n",
            "Valid Loss: 0.0136\n",
            "Epoch [34/1000]\n",
            "Train Loss: 0.0027\n",
            "Valid Loss: 0.0132\n",
            "Epoch [35/1000]\n",
            "Train Loss: 0.0039\n",
            "Valid Loss: 0.0152\n",
            "Epoch [36/1000]\n",
            "Train Loss: 0.0032\n",
            "Valid Loss: 0.0140\n",
            "Epoch [37/1000]\n",
            "Train Loss: 0.0039\n",
            "Valid Loss: 0.0162\n",
            "Epoch [38/1000]\n",
            "Train Loss: 0.0033\n",
            "Valid Loss: 0.0156\n",
            "Epoch [39/1000]\n",
            "Train Loss: 0.0034\n",
            "Valid Loss: 0.0179\n",
            "Epoch [40/1000]\n",
            "Train Loss: 0.0064\n",
            "Valid Loss: 0.0179\n",
            "Epoch [41/1000]\n",
            "Train Loss: 0.0059\n",
            "Valid Loss: 0.0203\n",
            "Epoch [42/1000]\n",
            "Train Loss: 0.0045\n",
            "Valid Loss: 0.0211\n",
            "Epoch [43/1000]\n",
            "Train Loss: 0.0031\n",
            "Valid Loss: 0.0269\n",
            "Epoch [44/1000]\n",
            "Train Loss: 0.0065\n",
            "Valid Loss: 0.0244\n",
            "Epoch [45/1000]\n",
            "Train Loss: 0.0048\n",
            "Valid Loss: 0.0286\n",
            "Epoch [46/1000]\n",
            "Train Loss: 0.0038\n",
            "Valid Loss: 0.0325\n",
            "Epoch [47/1000]\n",
            "Train Loss: 0.0028\n",
            "Valid Loss: 0.0314\n",
            "Epoch [48/1000]\n",
            "Train Loss: 0.0041\n",
            "Valid Loss: 0.0321\n",
            "Epoch [49/1000]\n",
            "Train Loss: 0.0037\n",
            "Valid Loss: 0.0401\n",
            "Epoch [50/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0405\n",
            "Epoch [51/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0369\n",
            "Epoch [52/1000]\n",
            "Train Loss: 0.0033\n",
            "Valid Loss: 0.0540\n",
            "Epoch [53/1000]\n",
            "Train Loss: 0.0037\n",
            "Valid Loss: 0.0358\n",
            "Epoch [54/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0491\n",
            "Epoch [55/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0379\n",
            "Epoch [56/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0509\n",
            "Epoch [57/1000]\n",
            "Train Loss: 0.0035\n",
            "Valid Loss: 0.0368\n",
            "Epoch [58/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0444\n",
            "Epoch [59/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0427\n",
            "Epoch [60/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0418\n",
            "Epoch [61/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0400\n",
            "Epoch [62/1000]\n",
            "Train Loss: 0.0028\n",
            "Valid Loss: 0.0460\n",
            "Epoch [63/1000]\n",
            "Train Loss: 0.0028\n",
            "Valid Loss: 0.0384\n",
            "Epoch [64/1000]\n",
            "Train Loss: 0.0035\n",
            "Valid Loss: 0.0371\n",
            "Epoch [65/1000]\n",
            "Train Loss: 0.0044\n",
            "Valid Loss: 0.0410\n",
            "Epoch [66/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0343\n",
            "Epoch [67/1000]\n",
            "Train Loss: 0.0027\n",
            "Valid Loss: 0.0365\n",
            "Epoch [68/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0392\n",
            "Epoch [69/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0454\n",
            "Epoch [70/1000]\n",
            "Train Loss: 0.0038\n",
            "Valid Loss: 0.0359\n",
            "Epoch [71/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0373\n",
            "Epoch [72/1000]\n",
            "Train Loss: 0.0042\n",
            "Valid Loss: 0.0343\n",
            "Epoch [73/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0371\n",
            "Epoch [74/1000]\n",
            "Train Loss: 0.0028\n",
            "Valid Loss: 0.0415\n",
            "Epoch [75/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0362\n",
            "Epoch [76/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0374\n",
            "Epoch [77/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0330\n",
            "Epoch [78/1000]\n",
            "Train Loss: 0.0026\n",
            "Valid Loss: 0.0351\n",
            "Epoch [79/1000]\n",
            "Train Loss: 0.0033\n",
            "Valid Loss: 0.0403\n",
            "Epoch [80/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0333\n",
            "Epoch [81/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0371\n",
            "Epoch [82/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0275\n",
            "Epoch [83/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0357\n",
            "Epoch [84/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0340\n",
            "Epoch [85/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0351\n",
            "Epoch [86/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0348\n",
            "Epoch [87/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0270\n",
            "Epoch [88/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0319\n",
            "Epoch [89/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0336\n",
            "Epoch [90/1000]\n",
            "Train Loss: 0.0035\n",
            "Valid Loss: 0.0359\n",
            "Epoch [91/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0321\n",
            "Epoch [92/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0320\n",
            "Epoch [93/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0321\n",
            "Epoch [94/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0398\n",
            "Epoch [95/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0311\n",
            "Epoch [96/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0340\n",
            "Epoch [97/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0313\n",
            "Epoch [98/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0303\n",
            "Epoch [99/1000]\n",
            "Train Loss: 0.0032\n",
            "Valid Loss: 0.0336\n",
            "Epoch [100/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0286\n",
            "Epoch [101/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0374\n",
            "Epoch [102/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0269\n",
            "Epoch [103/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0323\n",
            "Epoch [104/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0217\n",
            "Epoch [105/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0407\n",
            "Epoch [106/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0273\n",
            "Epoch [107/1000]\n",
            "Train Loss: 0.0028\n",
            "Valid Loss: 0.0326\n",
            "Epoch [108/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0215\n",
            "Epoch [109/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0317\n",
            "Epoch [110/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0245\n",
            "Epoch [111/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0285\n",
            "Epoch [112/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0283\n",
            "Epoch [113/1000]\n",
            "Train Loss: 0.0031\n",
            "Valid Loss: 0.0283\n",
            "Epoch [114/1000]\n",
            "Train Loss: 0.0026\n",
            "Valid Loss: 0.0240\n",
            "Epoch [115/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0325\n",
            "Epoch [116/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0240\n",
            "Epoch [117/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0296\n",
            "Epoch [118/1000]\n",
            "Train Loss: 0.0027\n",
            "Valid Loss: 0.0242\n",
            "Epoch [119/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0257\n",
            "Epoch [120/1000]\n",
            "Train Loss: 0.0033\n",
            "Valid Loss: 0.0336\n",
            "Epoch [121/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0219\n",
            "Epoch [122/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0311\n",
            "Epoch [123/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0235\n",
            "Epoch [124/1000]\n",
            "Train Loss: 0.0031\n",
            "Valid Loss: 0.0300\n",
            "Epoch [125/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0208\n",
            "Epoch [126/1000]\n",
            "Train Loss: 0.0026\n",
            "Valid Loss: 0.0240\n",
            "Epoch [127/1000]\n",
            "Train Loss: 0.0036\n",
            "Valid Loss: 0.0211\n",
            "Epoch [128/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0331\n",
            "Epoch [129/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0221\n",
            "Epoch [130/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0235\n",
            "Epoch [131/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0239\n",
            "Epoch [132/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0221\n",
            "Epoch [133/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0212\n",
            "Epoch [134/1000]\n",
            "Train Loss: 0.0031\n",
            "Valid Loss: 0.0226\n",
            "Epoch [135/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0201\n",
            "Epoch [136/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0232\n",
            "Epoch [137/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0223\n",
            "Epoch [138/1000]\n",
            "Train Loss: 0.0036\n",
            "Valid Loss: 0.0223\n",
            "Epoch [139/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0142\n",
            "Epoch [140/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0237\n",
            "Epoch [141/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0184\n",
            "Epoch [142/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0266\n",
            "Epoch [143/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0193\n",
            "Epoch [144/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0224\n",
            "Epoch [145/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0232\n",
            "Epoch [146/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0199\n",
            "Epoch [147/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0218\n",
            "Epoch [148/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0218\n",
            "Epoch [149/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0285\n",
            "Epoch [150/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0213\n",
            "Epoch [151/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0251\n",
            "Epoch [152/1000]\n",
            "Train Loss: 0.0031\n",
            "Valid Loss: 0.0205\n",
            "Epoch [153/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0244\n",
            "Epoch [154/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0235\n",
            "Epoch [155/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0241\n",
            "Epoch [156/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0243\n",
            "Epoch [157/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0232\n",
            "Epoch [158/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0287\n",
            "Epoch [159/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0192\n",
            "Epoch [160/1000]\n",
            "Train Loss: 0.0022\n",
            "Valid Loss: 0.0248\n",
            "Epoch [161/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0157\n",
            "Epoch [162/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0279\n",
            "Epoch [163/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0212\n",
            "Epoch [164/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0245\n",
            "Epoch [165/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0227\n",
            "Epoch [166/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0270\n",
            "Epoch [167/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0274\n",
            "Epoch [168/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0219\n",
            "Epoch [169/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0237\n",
            "Epoch [170/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0247\n",
            "Epoch [171/1000]\n",
            "Train Loss: 0.0027\n",
            "Valid Loss: 0.0266\n",
            "Epoch [172/1000]\n",
            "Train Loss: 0.0027\n",
            "Valid Loss: 0.0262\n",
            "Epoch [173/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0232\n",
            "Epoch [174/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0304\n",
            "Epoch [175/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0204\n",
            "Epoch [176/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0241\n",
            "Epoch [177/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0213\n",
            "Epoch [178/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0243\n",
            "Epoch [179/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0220\n",
            "Epoch [180/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0306\n",
            "Epoch [181/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0243\n",
            "Epoch [182/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0301\n",
            "Epoch [183/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0272\n",
            "Epoch [184/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0297\n",
            "Epoch [185/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0260\n",
            "Epoch [186/1000]\n",
            "Train Loss: 0.0023\n",
            "Valid Loss: 0.0243\n",
            "Epoch [187/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0244\n",
            "Epoch [188/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0287\n",
            "Epoch [189/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0217\n",
            "Epoch [190/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0273\n",
            "Epoch [191/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0290\n",
            "Epoch [192/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0310\n",
            "Epoch [193/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0196\n",
            "Epoch [194/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0314\n",
            "Epoch [195/1000]\n",
            "Train Loss: 0.0030\n",
            "Valid Loss: 0.0269\n",
            "Epoch [196/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0273\n",
            "Epoch [197/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0236\n",
            "Epoch [198/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0360\n",
            "Epoch [199/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0204\n",
            "Epoch [200/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0338\n",
            "Epoch [201/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0266\n",
            "Epoch [202/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0261\n",
            "Epoch [203/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0262\n",
            "Epoch [204/1000]\n",
            "Train Loss: 0.0021\n",
            "Valid Loss: 0.0248\n",
            "Epoch [205/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0350\n",
            "Epoch [206/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0210\n",
            "Epoch [207/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0354\n",
            "Epoch [208/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0255\n",
            "Epoch [209/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0305\n",
            "Epoch [210/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0240\n",
            "Epoch [211/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0262\n",
            "Epoch [212/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0271\n",
            "Epoch [213/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0275\n",
            "Epoch [214/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0260\n",
            "Epoch [215/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0362\n",
            "Epoch [216/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0201\n",
            "Epoch [217/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0302\n",
            "Epoch [218/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0278\n",
            "Epoch [219/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0328\n",
            "Epoch [220/1000]\n",
            "Train Loss: 0.0024\n",
            "Valid Loss: 0.0139\n",
            "Epoch [221/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0222\n",
            "Epoch [222/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0387\n",
            "Epoch [223/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0230\n",
            "Epoch [224/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0246\n",
            "Epoch [225/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0140\n",
            "Epoch [226/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0347\n",
            "Epoch [227/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0243\n",
            "Epoch [228/1000]\n",
            "Train Loss: 0.0026\n",
            "Valid Loss: 0.0281\n",
            "Epoch [229/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0203\n",
            "Epoch [230/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0293\n",
            "Epoch [231/1000]\n",
            "Train Loss: 0.0028\n",
            "Valid Loss: 0.0270\n",
            "Epoch [232/1000]\n",
            "Train Loss: 0.0034\n",
            "Valid Loss: 0.0190\n",
            "Epoch [233/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0305\n",
            "Epoch [234/1000]\n",
            "Train Loss: 0.0029\n",
            "Valid Loss: 0.0241\n",
            "Epoch [235/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0302\n",
            "Epoch [236/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0249\n",
            "Epoch [237/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0285\n",
            "Epoch [238/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0276\n",
            "Epoch [239/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0275\n",
            "Epoch [240/1000]\n",
            "Train Loss: 0.0025\n",
            "Valid Loss: 0.0264\n",
            "Epoch [241/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0239\n",
            "Epoch [242/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0330\n",
            "Epoch [243/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0236\n",
            "Epoch [244/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0280\n",
            "Epoch [245/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0318\n",
            "Epoch [246/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0252\n",
            "Epoch [247/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0292\n",
            "Epoch [248/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0259\n",
            "Epoch [249/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0295\n",
            "Epoch [250/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0321\n",
            "Epoch [251/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0263\n",
            "Epoch [252/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0244\n",
            "Epoch [253/1000]\n",
            "Train Loss: 0.0020\n",
            "Valid Loss: 0.0274\n",
            "Epoch [254/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0253\n",
            "Epoch [255/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0332\n",
            "Epoch [256/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0245\n",
            "Epoch [257/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0242\n",
            "Epoch [258/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0263\n",
            "Epoch [259/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0299\n",
            "Epoch [260/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0343\n",
            "Epoch [261/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0329\n",
            "Epoch [262/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0248\n",
            "Epoch [263/1000]\n",
            "Train Loss: 0.0018\n",
            "Valid Loss: 0.0274\n",
            "Epoch [264/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0293\n",
            "Epoch [265/1000]\n",
            "Train Loss: 0.0019\n",
            "Valid Loss: 0.0279\n",
            "Epoch [266/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0267\n",
            "Epoch [267/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0292\n",
            "Epoch [268/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0280\n",
            "Epoch [269/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0270\n",
            "Epoch [270/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0302\n",
            "Epoch [271/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0252\n",
            "Epoch [272/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0349\n",
            "Epoch [273/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0301\n",
            "Epoch [274/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0324\n",
            "Epoch [275/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0405\n",
            "Epoch [276/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0276\n",
            "Epoch [277/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0282\n",
            "Epoch [278/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0295\n",
            "Epoch [279/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0312\n",
            "Epoch [280/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0212\n",
            "Epoch [281/1000]\n",
            "Train Loss: 0.0016\n",
            "Valid Loss: 0.0310\n",
            "Epoch [282/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0339\n",
            "Epoch [283/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0344\n",
            "Epoch [284/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0232\n",
            "Epoch [285/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0347\n",
            "Epoch [286/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0274\n",
            "Epoch [287/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0358\n",
            "Epoch [288/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0233\n",
            "Epoch [289/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0323\n",
            "Epoch [290/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0246\n",
            "Epoch [291/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0300\n",
            "Epoch [292/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0267\n",
            "Epoch [293/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0289\n",
            "Epoch [294/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0293\n",
            "Epoch [295/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0292\n",
            "Epoch [296/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0265\n",
            "Epoch [297/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0347\n",
            "Epoch [298/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0256\n",
            "Epoch [299/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0358\n",
            "Epoch [300/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0224\n",
            "Epoch [301/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0281\n",
            "Epoch [302/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0331\n",
            "Epoch [303/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0304\n",
            "Epoch [304/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0279\n",
            "Epoch [305/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0409\n",
            "Epoch [306/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0218\n",
            "Epoch [307/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0381\n",
            "Epoch [308/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0195\n",
            "Epoch [309/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0204\n",
            "Epoch [310/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0266\n",
            "Epoch [311/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0256\n",
            "Epoch [312/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0247\n",
            "Epoch [313/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0291\n",
            "Epoch [314/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0364\n",
            "Epoch [315/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0332\n",
            "Epoch [316/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0349\n",
            "Epoch [317/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0298\n",
            "Epoch [318/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0396\n",
            "Epoch [319/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0262\n",
            "Epoch [320/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0343\n",
            "Epoch [321/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0249\n",
            "Epoch [322/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0472\n",
            "Epoch [323/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0287\n",
            "Epoch [324/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0277\n",
            "Epoch [325/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0298\n",
            "Epoch [326/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0341\n",
            "Epoch [327/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0299\n",
            "Epoch [328/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0315\n",
            "Epoch [329/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0340\n",
            "Epoch [330/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0290\n",
            "Epoch [331/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0296\n",
            "Epoch [332/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0309\n",
            "Epoch [333/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0297\n",
            "Epoch [334/1000]\n",
            "Train Loss: 0.0015\n",
            "Valid Loss: 0.0293\n",
            "Epoch [335/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0318\n",
            "Epoch [336/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0242\n",
            "Epoch [337/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0278\n",
            "Epoch [338/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0504\n",
            "Epoch [339/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0310\n",
            "Epoch [340/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0306\n",
            "Epoch [341/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0312\n",
            "Epoch [342/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0328\n",
            "Epoch [343/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0293\n",
            "Epoch [344/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0332\n",
            "Epoch [345/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0313\n",
            "Epoch [346/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0234\n",
            "Epoch [347/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0352\n",
            "Epoch [348/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0333\n",
            "Epoch [349/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0329\n",
            "Epoch [350/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0350\n",
            "Epoch [351/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0323\n",
            "Epoch [352/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0288\n",
            "Epoch [353/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0366\n",
            "Epoch [354/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0264\n",
            "Epoch [355/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0287\n",
            "Epoch [356/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0265\n",
            "Epoch [357/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0317\n",
            "Epoch [358/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0228\n",
            "Epoch [359/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0296\n",
            "Epoch [360/1000]\n",
            "Train Loss: 0.0017\n",
            "Valid Loss: 0.0317\n",
            "Epoch [361/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0274\n",
            "Epoch [362/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0314\n",
            "Epoch [363/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0272\n",
            "Epoch [364/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0301\n",
            "Epoch [365/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0268\n",
            "Epoch [366/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0339\n",
            "Epoch [367/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0243\n",
            "Epoch [368/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0300\n",
            "Epoch [369/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0316\n",
            "Epoch [370/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0257\n",
            "Epoch [371/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0289\n",
            "Epoch [372/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0245\n",
            "Epoch [373/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0309\n",
            "Epoch [374/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0218\n",
            "Epoch [375/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0337\n",
            "Epoch [376/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0229\n",
            "Epoch [377/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0261\n",
            "Epoch [378/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0251\n",
            "Epoch [379/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0205\n",
            "Epoch [380/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0306\n",
            "Epoch [381/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0232\n",
            "Epoch [382/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0288\n",
            "Epoch [383/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0210\n",
            "Epoch [384/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0244\n",
            "Epoch [385/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0243\n",
            "Epoch [386/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0204\n",
            "Epoch [387/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0224\n",
            "Epoch [388/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0255\n",
            "Epoch [389/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0296\n",
            "Epoch [390/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0228\n",
            "Epoch [391/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0219\n",
            "Epoch [392/1000]\n",
            "Train Loss: 0.0014\n",
            "Valid Loss: 0.0192\n",
            "Epoch [393/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0255\n",
            "Epoch [394/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0244\n",
            "Epoch [395/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0188\n",
            "Epoch [396/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0231\n",
            "Epoch [397/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0195\n",
            "Epoch [398/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0202\n",
            "Epoch [399/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0195\n",
            "Epoch [400/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0292\n",
            "Epoch [401/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0219\n",
            "Epoch [402/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0226\n",
            "Epoch [403/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0248\n",
            "Epoch [404/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0232\n",
            "Epoch [405/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0278\n",
            "Epoch [406/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0279\n",
            "Epoch [407/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0246\n",
            "Epoch [408/1000]\n",
            "Train Loss: 0.0013\n",
            "Valid Loss: 0.0262\n",
            "Epoch [409/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0269\n",
            "Epoch [410/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0191\n",
            "Epoch [411/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0261\n",
            "Epoch [412/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0235\n",
            "Epoch [413/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0272\n",
            "Epoch [414/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0204\n",
            "Epoch [415/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0328\n",
            "Epoch [416/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0243\n",
            "Epoch [417/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0253\n",
            "Epoch [418/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0213\n",
            "Epoch [419/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0240\n",
            "Epoch [420/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0233\n",
            "Epoch [421/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0216\n",
            "Epoch [422/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0281\n",
            "Epoch [423/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0194\n",
            "Epoch [424/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0301\n",
            "Epoch [425/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0218\n",
            "Epoch [426/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0270\n",
            "Epoch [427/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0242\n",
            "Epoch [428/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0240\n",
            "Epoch [429/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0247\n",
            "Epoch [430/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0250\n",
            "Epoch [431/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0271\n",
            "Epoch [432/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0204\n",
            "Epoch [433/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0257\n",
            "Epoch [434/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0253\n",
            "Epoch [435/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0243\n",
            "Epoch [436/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0286\n",
            "Epoch [437/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0210\n",
            "Epoch [438/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0216\n",
            "Epoch [439/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0284\n",
            "Epoch [440/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0207\n",
            "Epoch [441/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0225\n",
            "Epoch [442/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0251\n",
            "Epoch [443/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0240\n",
            "Epoch [444/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0238\n",
            "Epoch [445/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0206\n",
            "Epoch [446/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0246\n",
            "Epoch [447/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0223\n",
            "Epoch [448/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0250\n",
            "Epoch [449/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0237\n",
            "Epoch [450/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0161\n",
            "Epoch [451/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0277\n",
            "Epoch [452/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0238\n",
            "Epoch [453/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0292\n",
            "Epoch [454/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0242\n",
            "Epoch [455/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0282\n",
            "Epoch [456/1000]\n",
            "Train Loss: 0.0012\n",
            "Valid Loss: 0.0266\n",
            "Epoch [457/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0246\n",
            "Epoch [458/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0260\n",
            "Epoch [459/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0254\n",
            "Epoch [460/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0296\n",
            "Epoch [461/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0217\n",
            "Epoch [462/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0257\n",
            "Epoch [463/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0255\n",
            "Epoch [464/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0248\n",
            "Epoch [465/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0253\n",
            "Epoch [466/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0237\n",
            "Epoch [467/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0248\n",
            "Epoch [468/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0240\n",
            "Epoch [469/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0325\n",
            "Epoch [470/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0214\n",
            "Epoch [471/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0303\n",
            "Epoch [472/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0212\n",
            "Epoch [473/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0288\n",
            "Epoch [474/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0278\n",
            "Epoch [475/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0236\n",
            "Epoch [476/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0266\n",
            "Epoch [477/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0262\n",
            "Epoch [478/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0255\n",
            "Epoch [479/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0251\n",
            "Epoch [480/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0282\n",
            "Epoch [481/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0267\n",
            "Epoch [482/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0248\n",
            "Epoch [483/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0230\n",
            "Epoch [484/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0255\n",
            "Epoch [485/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0214\n",
            "Epoch [486/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0304\n",
            "Epoch [487/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0245\n",
            "Epoch [488/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0267\n",
            "Epoch [489/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0272\n",
            "Epoch [490/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0260\n",
            "Epoch [491/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0238\n",
            "Epoch [492/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0336\n",
            "Epoch [493/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0234\n",
            "Epoch [494/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0308\n",
            "Epoch [495/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0230\n",
            "Epoch [496/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0279\n",
            "Epoch [497/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0288\n",
            "Epoch [498/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0288\n",
            "Epoch [499/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0290\n",
            "Epoch [500/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0265\n",
            "Epoch [501/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0240\n",
            "Epoch [502/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0290\n",
            "Epoch [503/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0246\n",
            "Epoch [504/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0291\n",
            "Epoch [505/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0223\n",
            "Epoch [506/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0338\n",
            "Epoch [507/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0255\n",
            "Epoch [508/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0331\n",
            "Epoch [509/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0290\n",
            "Epoch [510/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0304\n",
            "Epoch [511/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0275\n",
            "Epoch [512/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0294\n",
            "Epoch [513/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0243\n",
            "Epoch [514/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0289\n",
            "Epoch [515/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0341\n",
            "Epoch [516/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0288\n",
            "Epoch [517/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0330\n",
            "Epoch [518/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0294\n",
            "Epoch [519/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0306\n",
            "Epoch [520/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0313\n",
            "Epoch [521/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0285\n",
            "Epoch [522/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0307\n",
            "Epoch [523/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0291\n",
            "Epoch [524/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0267\n",
            "Epoch [525/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0347\n",
            "Epoch [526/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0291\n",
            "Epoch [527/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0332\n",
            "Epoch [528/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0304\n",
            "Epoch [529/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0272\n",
            "Epoch [530/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0331\n",
            "Epoch [531/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0297\n",
            "Epoch [532/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0329\n",
            "Epoch [533/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0280\n",
            "Epoch [534/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0317\n",
            "Epoch [535/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0324\n",
            "Epoch [536/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0331\n",
            "Epoch [537/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0307\n",
            "Epoch [538/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0279\n",
            "Epoch [539/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0314\n",
            "Epoch [540/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0288\n",
            "Epoch [541/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0383\n",
            "Epoch [542/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0312\n",
            "Epoch [543/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0367\n",
            "Epoch [544/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0318\n",
            "Epoch [545/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0334\n",
            "Epoch [546/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0310\n",
            "Epoch [547/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0328\n",
            "Epoch [548/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0337\n",
            "Epoch [549/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0316\n",
            "Epoch [550/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0332\n",
            "Epoch [551/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0321\n",
            "Epoch [552/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0322\n",
            "Epoch [553/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0275\n",
            "Epoch [554/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0341\n",
            "Epoch [555/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0300\n",
            "Epoch [556/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0369\n",
            "Epoch [557/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0319\n",
            "Epoch [558/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0352\n",
            "Epoch [559/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0316\n",
            "Epoch [560/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0320\n",
            "Epoch [561/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0331\n",
            "Epoch [562/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0329\n",
            "Epoch [563/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0335\n",
            "Epoch [564/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0340\n",
            "Epoch [565/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0340\n",
            "Epoch [566/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0324\n",
            "Epoch [567/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0345\n",
            "Epoch [568/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0339\n",
            "Epoch [569/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0336\n",
            "Epoch [570/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0327\n",
            "Epoch [571/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0382\n",
            "Epoch [572/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0269\n",
            "Epoch [573/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0355\n",
            "Epoch [574/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0308\n",
            "Epoch [575/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0343\n",
            "Epoch [576/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0316\n",
            "Epoch [577/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0366\n",
            "Epoch [578/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0322\n",
            "Epoch [579/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0338\n",
            "Epoch [580/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0339\n",
            "Epoch [581/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0349\n",
            "Epoch [582/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0321\n",
            "Epoch [583/1000]\n",
            "Train Loss: 0.0011\n",
            "Valid Loss: 0.0311\n",
            "Epoch [584/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0380\n",
            "Epoch [585/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0347\n",
            "Epoch [586/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0347\n",
            "Epoch [587/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0367\n",
            "Epoch [588/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0330\n",
            "Epoch [589/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0361\n",
            "Epoch [590/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0270\n",
            "Epoch [591/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0431\n",
            "Epoch [592/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0260\n",
            "Epoch [593/1000]\n",
            "Train Loss: 0.0010\n",
            "Valid Loss: 0.0418\n",
            "Epoch [594/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0320\n",
            "Epoch [595/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0405\n",
            "Epoch [596/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0307\n",
            "Epoch [597/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0429\n",
            "Epoch [598/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0296\n",
            "Epoch [599/1000]\n",
            "Train Loss: 0.0008\n",
            "Valid Loss: 0.0336\n",
            "Epoch [600/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0398\n",
            "Epoch [601/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0349\n",
            "Epoch [602/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0385\n",
            "Epoch [603/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0374\n",
            "Epoch [604/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0363\n",
            "Epoch [605/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0389\n",
            "Epoch [606/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0353\n",
            "Epoch [607/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0418\n",
            "Epoch [608/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0349\n",
            "Epoch [609/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0400\n",
            "Epoch [610/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0373\n",
            "Epoch [611/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0359\n",
            "Epoch [612/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0398\n",
            "Epoch [613/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0372\n",
            "Epoch [614/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0374\n",
            "Epoch [615/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0370\n",
            "Epoch [616/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0371\n",
            "Epoch [617/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0378\n",
            "Epoch [618/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0374\n",
            "Epoch [619/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0357\n",
            "Epoch [620/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0415\n",
            "Epoch [621/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0354\n",
            "Epoch [622/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0365\n",
            "Epoch [623/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0381\n",
            "Epoch [624/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0383\n",
            "Epoch [625/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0383\n",
            "Epoch [626/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0361\n",
            "Epoch [627/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0377\n",
            "Epoch [628/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0379\n",
            "Epoch [629/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0396\n",
            "Epoch [630/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0364\n",
            "Epoch [631/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0377\n",
            "Epoch [632/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0360\n",
            "Epoch [633/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0402\n",
            "Epoch [634/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0398\n",
            "Epoch [635/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0382\n",
            "Epoch [636/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0354\n",
            "Epoch [637/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0379\n",
            "Epoch [638/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0384\n",
            "Epoch [639/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0365\n",
            "Epoch [640/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0395\n",
            "Epoch [641/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0367\n",
            "Epoch [642/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0403\n",
            "Epoch [643/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0345\n",
            "Epoch [644/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0412\n",
            "Epoch [645/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0350\n",
            "Epoch [646/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0386\n",
            "Epoch [647/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0379\n",
            "Epoch [648/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0384\n",
            "Epoch [649/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0365\n",
            "Epoch [650/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0412\n",
            "Epoch [651/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0349\n",
            "Epoch [652/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0414\n",
            "Epoch [653/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0354\n",
            "Epoch [654/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0390\n",
            "Epoch [655/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0381\n",
            "Epoch [656/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0385\n",
            "Epoch [657/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0401\n",
            "Epoch [658/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0380\n",
            "Epoch [659/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0406\n",
            "Epoch [660/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0351\n",
            "Epoch [661/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0415\n",
            "Epoch [662/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0354\n",
            "Epoch [663/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0425\n",
            "Epoch [664/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0346\n",
            "Epoch [665/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0405\n",
            "Epoch [666/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0320\n",
            "Epoch [667/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0485\n",
            "Epoch [668/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0357\n",
            "Epoch [669/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0415\n",
            "Epoch [670/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0395\n",
            "Epoch [671/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0373\n",
            "Epoch [672/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0389\n",
            "Epoch [673/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0393\n",
            "Epoch [674/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0400\n",
            "Epoch [675/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0382\n",
            "Epoch [676/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0398\n",
            "Epoch [677/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0387\n",
            "Epoch [678/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0392\n",
            "Epoch [679/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0389\n",
            "Epoch [680/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0367\n",
            "Epoch [681/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0435\n",
            "Epoch [682/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0358\n",
            "Epoch [683/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0413\n",
            "Epoch [684/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0391\n",
            "Epoch [685/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0404\n",
            "Epoch [686/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0389\n",
            "Epoch [687/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0406\n",
            "Epoch [688/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0396\n",
            "Epoch [689/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0403\n",
            "Epoch [690/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0385\n",
            "Epoch [691/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0384\n",
            "Epoch [692/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0432\n",
            "Epoch [693/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0375\n",
            "Epoch [694/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0417\n",
            "Epoch [695/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0406\n",
            "Epoch [696/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0395\n",
            "Epoch [697/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0399\n",
            "Epoch [698/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0416\n",
            "Epoch [699/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0391\n",
            "Epoch [700/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0420\n",
            "Epoch [701/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0392\n",
            "Epoch [702/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0400\n",
            "Epoch [703/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0420\n",
            "Epoch [704/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0414\n",
            "Epoch [705/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0387\n",
            "Epoch [706/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0425\n",
            "Epoch [707/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0424\n",
            "Epoch [708/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0400\n",
            "Epoch [709/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0414\n",
            "Epoch [710/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0425\n",
            "Epoch [711/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0415\n",
            "Epoch [712/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0398\n",
            "Epoch [713/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0405\n",
            "Epoch [714/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0406\n",
            "Epoch [715/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0428\n",
            "Epoch [716/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0401\n",
            "Epoch [717/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0452\n",
            "Epoch [718/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0417\n",
            "Epoch [719/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0434\n",
            "Epoch [720/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0410\n",
            "Epoch [721/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0406\n",
            "Epoch [722/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0418\n",
            "Epoch [723/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0428\n",
            "Epoch [724/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0403\n",
            "Epoch [725/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0432\n",
            "Epoch [726/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0407\n",
            "Epoch [727/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0443\n",
            "Epoch [728/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0413\n",
            "Epoch [729/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0406\n",
            "Epoch [730/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0414\n",
            "Epoch [731/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0443\n",
            "Epoch [732/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0395\n",
            "Epoch [733/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0442\n",
            "Epoch [734/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0420\n",
            "Epoch [735/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0409\n",
            "Epoch [736/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0430\n",
            "Epoch [737/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0415\n",
            "Epoch [738/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0446\n",
            "Epoch [739/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0415\n",
            "Epoch [740/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0427\n",
            "Epoch [741/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0412\n",
            "Epoch [742/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0420\n",
            "Epoch [743/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0427\n",
            "Epoch [744/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0426\n",
            "Epoch [745/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0420\n",
            "Epoch [746/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0428\n",
            "Epoch [747/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0412\n",
            "Epoch [748/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0417\n",
            "Epoch [749/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0425\n",
            "Epoch [750/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0423\n",
            "Epoch [751/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0418\n",
            "Epoch [752/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0449\n",
            "Epoch [753/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0401\n",
            "Epoch [754/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0458\n",
            "Epoch [755/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0399\n",
            "Epoch [756/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0468\n",
            "Epoch [757/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0403\n",
            "Epoch [758/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0423\n",
            "Epoch [759/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0441\n",
            "Epoch [760/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0412\n",
            "Epoch [761/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0429\n",
            "Epoch [762/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0438\n",
            "Epoch [763/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0415\n",
            "Epoch [764/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0434\n",
            "Epoch [765/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0423\n",
            "Epoch [766/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0441\n",
            "Epoch [767/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0443\n",
            "Epoch [768/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0424\n",
            "Epoch [769/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0429\n",
            "Epoch [770/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0444\n",
            "Epoch [771/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0446\n",
            "Epoch [772/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0424\n",
            "Epoch [773/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0431\n",
            "Epoch [774/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0448\n",
            "Epoch [775/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0435\n",
            "Epoch [776/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0419\n",
            "Epoch [777/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0447\n",
            "Epoch [778/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0412\n",
            "Epoch [779/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0421\n",
            "Epoch [780/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0449\n",
            "Epoch [781/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0444\n",
            "Epoch [782/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0427\n",
            "Epoch [783/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0422\n",
            "Epoch [784/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0429\n",
            "Epoch [785/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0415\n",
            "Epoch [786/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0448\n",
            "Epoch [787/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0415\n",
            "Epoch [788/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0429\n",
            "Epoch [789/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0403\n",
            "Epoch [790/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0462\n",
            "Epoch [791/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0422\n",
            "Epoch [792/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0433\n",
            "Epoch [793/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0435\n",
            "Epoch [794/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0417\n",
            "Epoch [795/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0434\n",
            "Epoch [796/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0446\n",
            "Epoch [797/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0415\n",
            "Epoch [798/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0420\n",
            "Epoch [799/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0435\n",
            "Epoch [800/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0461\n",
            "Epoch [801/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0407\n",
            "Epoch [802/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0461\n",
            "Epoch [803/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0409\n",
            "Epoch [804/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0450\n",
            "Epoch [805/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0421\n",
            "Epoch [806/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0436\n",
            "Epoch [807/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0456\n",
            "Epoch [808/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0425\n",
            "Epoch [809/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0430\n",
            "Epoch [810/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0458\n",
            "Epoch [811/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0413\n",
            "Epoch [812/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0449\n",
            "Epoch [813/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0412\n",
            "Epoch [814/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0454\n",
            "Epoch [815/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0433\n",
            "Epoch [816/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0417\n",
            "Epoch [817/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0445\n",
            "Epoch [818/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0443\n",
            "Epoch [819/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0439\n",
            "Epoch [820/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0438\n",
            "Epoch [821/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0426\n",
            "Epoch [822/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0413\n",
            "Epoch [823/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0438\n",
            "Epoch [824/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0442\n",
            "Epoch [825/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0410\n",
            "Epoch [826/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0456\n",
            "Epoch [827/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0421\n",
            "Epoch [828/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0415\n",
            "Epoch [829/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0435\n",
            "Epoch [830/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0458\n",
            "Epoch [831/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0422\n",
            "Epoch [832/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0401\n",
            "Epoch [833/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0455\n",
            "Epoch [834/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0448\n",
            "Epoch [835/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0414\n",
            "Epoch [836/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0444\n",
            "Epoch [837/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0447\n",
            "Epoch [838/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0474\n",
            "Epoch [839/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0430\n",
            "Epoch [840/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0435\n",
            "Epoch [841/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0451\n",
            "Epoch [842/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0438\n",
            "Epoch [843/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0476\n",
            "Epoch [844/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0399\n",
            "Epoch [845/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0439\n",
            "Epoch [846/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0438\n",
            "Epoch [847/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0442\n",
            "Epoch [848/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0440\n",
            "Epoch [849/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0445\n",
            "Epoch [850/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0431\n",
            "Epoch [851/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0456\n",
            "Epoch [852/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0441\n",
            "Epoch [853/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0436\n",
            "Epoch [854/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0463\n",
            "Epoch [855/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0416\n",
            "Epoch [856/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0472\n",
            "Epoch [857/1000]\n",
            "Train Loss: 0.0006\n",
            "Valid Loss: 0.0411\n",
            "Epoch [858/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0431\n",
            "Epoch [859/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0461\n",
            "Epoch [860/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0420\n",
            "Epoch [861/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0463\n",
            "Epoch [862/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0414\n",
            "Epoch [863/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0451\n",
            "Epoch [864/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0421\n",
            "Epoch [865/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0459\n",
            "Epoch [866/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0453\n",
            "Epoch [867/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0447\n",
            "Epoch [868/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0450\n",
            "Epoch [869/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0416\n",
            "Epoch [870/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0468\n",
            "Epoch [871/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0457\n",
            "Epoch [872/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0431\n",
            "Epoch [873/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0431\n",
            "Epoch [874/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0450\n",
            "Epoch [875/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0426\n",
            "Epoch [876/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0484\n",
            "Epoch [877/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0407\n",
            "Epoch [878/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0458\n",
            "Epoch [879/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0437\n",
            "Epoch [880/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0436\n",
            "Epoch [881/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0455\n",
            "Epoch [882/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0417\n",
            "Epoch [883/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0500\n",
            "Epoch [884/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0429\n",
            "Epoch [885/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0419\n",
            "Epoch [886/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0478\n",
            "Epoch [887/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0456\n",
            "Epoch [888/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0477\n",
            "Epoch [889/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0381\n",
            "Epoch [890/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0518\n",
            "Epoch [891/1000]\n",
            "Train Loss: 0.0004\n",
            "Valid Loss: 0.0422\n",
            "Epoch [892/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0559\n",
            "Epoch [893/1000]\n",
            "Train Loss: 0.0009\n",
            "Valid Loss: 0.0438\n",
            "Epoch [894/1000]\n",
            "Train Loss: 0.0007\n",
            "Valid Loss: 0.0427\n",
            "Epoch [895/1000]\n",
            "Train Loss: 0.0005\n",
            "Valid Loss: 0.0476\n",
            "Epoch [896/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0424\n",
            "Epoch [897/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0484\n",
            "Epoch [898/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0432\n",
            "Epoch [899/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0460\n",
            "Epoch [900/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0466\n",
            "Epoch [901/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0473\n",
            "Epoch [902/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0435\n",
            "Epoch [903/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0459\n",
            "Epoch [904/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0501\n",
            "Epoch [905/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0428\n",
            "Epoch [906/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0475\n",
            "Epoch [907/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0434\n",
            "Epoch [908/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0487\n",
            "Epoch [909/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0465\n",
            "Epoch [910/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0455\n",
            "Epoch [911/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0440\n",
            "Epoch [912/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0478\n",
            "Epoch [913/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0444\n",
            "Epoch [914/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0495\n",
            "Epoch [915/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0448\n",
            "Epoch [916/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0483\n",
            "Epoch [917/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0445\n",
            "Epoch [918/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0471\n",
            "Epoch [919/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0458\n",
            "Epoch [920/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0453\n",
            "Epoch [921/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0464\n",
            "Epoch [922/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0437\n",
            "Epoch [923/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0483\n",
            "Epoch [924/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0452\n",
            "Epoch [925/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0460\n",
            "Epoch [926/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0462\n",
            "Epoch [927/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0454\n",
            "Epoch [928/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0469\n",
            "Epoch [929/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0470\n",
            "Epoch [930/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0467\n",
            "Epoch [931/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0455\n",
            "Epoch [932/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0464\n",
            "Epoch [933/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0456\n",
            "Epoch [934/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0472\n",
            "Epoch [935/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0468\n",
            "Epoch [936/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0452\n",
            "Epoch [937/1000]\n",
            "Train Loss: 0.0000\n",
            "Valid Loss: 0.0469\n",
            "Epoch [938/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0453\n",
            "Epoch [939/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0486\n",
            "Epoch [940/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0452\n",
            "Epoch [941/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0460\n",
            "Epoch [942/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0435\n",
            "Epoch [943/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0487\n",
            "Epoch [944/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0425\n",
            "Epoch [945/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0487\n",
            "Epoch [946/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0419\n",
            "Epoch [947/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0451\n",
            "Epoch [948/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0451\n",
            "Epoch [949/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0483\n",
            "Epoch [950/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0425\n",
            "Epoch [951/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0449\n",
            "Epoch [952/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0466\n",
            "Epoch [953/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0441\n",
            "Epoch [954/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0426\n",
            "Epoch [955/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0458\n",
            "Epoch [956/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0458\n",
            "Epoch [957/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0431\n",
            "Epoch [958/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0448\n",
            "Epoch [959/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0450\n",
            "Epoch [960/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0470\n",
            "Epoch [961/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0456\n",
            "Epoch [962/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0445\n",
            "Epoch [963/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0462\n",
            "Epoch [964/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0445\n",
            "Epoch [965/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0446\n",
            "Epoch [966/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0447\n",
            "Epoch [967/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0441\n",
            "Epoch [968/1000]\n",
            "Train Loss: 0.0000\n",
            "Valid Loss: 0.0465\n",
            "Epoch [969/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0432\n",
            "Epoch [970/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0460\n",
            "Epoch [971/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0435\n",
            "Epoch [972/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0458\n",
            "Epoch [973/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0444\n",
            "Epoch [974/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0435\n",
            "Epoch [975/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0442\n",
            "Epoch [976/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0462\n",
            "Epoch [977/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0433\n",
            "Epoch [978/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0450\n",
            "Epoch [979/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0431\n",
            "Epoch [980/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0454\n",
            "Epoch [981/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0451\n",
            "Epoch [982/1000]\n",
            "Train Loss: 0.0000\n",
            "Valid Loss: 0.0460\n",
            "Epoch [983/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0431\n",
            "Epoch [984/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0449\n",
            "Epoch [985/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0450\n",
            "Epoch [986/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0448\n",
            "Epoch [987/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0431\n",
            "Epoch [988/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0456\n",
            "Epoch [989/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0446\n",
            "Epoch [990/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0434\n",
            "Epoch [991/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0460\n",
            "Epoch [992/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0410\n",
            "Epoch [993/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0468\n",
            "Epoch [994/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0420\n",
            "Epoch [995/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0435\n",
            "Epoch [996/1000]\n",
            "Train Loss: 0.0002\n",
            "Valid Loss: 0.0425\n",
            "Epoch [997/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0441\n",
            "Epoch [998/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0449\n",
            "Epoch [999/1000]\n",
            "Train Loss: 0.0001\n",
            "Valid Loss: 0.0430\n",
            "Epoch [1000/1000]\n",
            "Train Loss: 0.0003\n",
            "Valid Loss: 0.0434\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "# Train\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets.unsqueeze(1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in valid_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets.unsqueeze(1))\n",
        "            print(f\"Valid Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "num_epochs = 1000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645f865a",
      "metadata": {
        "id": "645f865a"
      },
      "source": [
        "### 5. Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3dfc657a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "3dfc657a",
        "outputId": "5b34a4b0-224c-4cfa-bda7-87b8be1d4994"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Result\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions.extend(outputs.squeeze().tolist())\n",
        "            actuals.extend(targets.tolist())\n",
        "    return predictions, actuals\n",
        "\n",
        "\n",
        "predictions, actuals = evaluate_model(model, test_loader)\n",
        "\n",
        "results = pd.DataFrame(\n",
        "    {\"Date\": test_dates, \"Actual\": actuals, \"Predicted\": predictions}\n",
        ")\n",
        "results.set_index('Date', inplace=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(results[\"Actual\"], label=\"Actual Close Prices\")\n",
        "plt.plot(results[\"Predicted\"], label=\"Predicted Close Prices\")\n",
        "plt.legend()\n",
        "plt.title(\"Samsung Stock Price Prediction\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.ylim(0, 1.5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}